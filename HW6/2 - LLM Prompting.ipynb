{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load patient data and imports",
   "id": "dad2ed8b25de6f84"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_url = \"http://localhost:11434/api/generate\"\n",
    "_headers = {\"Content-Type\": \"application/json\"}\n",
    "patients_original = pandas.read_csv(\"data/allergy_patients.csv\", low_memory=False)\n",
    "\n",
    "print(f\"Patients: {len(patients_original):,}\")\n",
    "\n",
    "new_dataset = False\n",
    "if new_dataset:\n",
    "    # Shuffle data\n",
    "    patients_shuffle = patients_original.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Save dataset to csv\n",
    "    patients_shuffle.to_csv('data/shuffled_data.csv', index=False, header=True)\n",
    "else:\n",
    "    # Used to load existing shuffle dataset. This is for testing on same set with different models.\n",
    "    patients_shuffle = pandas.read_csv(\"data/shuffled_data.csv\", low_memory=False)\n",
    "\n",
    "allergy_patients = patients_shuffle[patients_shuffle[\"is_allergy\"] == 1].sample(n=2, random_state=1)\n",
    "\n",
    "# Shot prompts\n",
    "zero_shot_prompt = f\"In a one word answer either 'True' or 'False' (no punctuation) and based on the following information, does the patient have an allergy?\"\n",
    "one_shot_prompt = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. In a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy?\"\n",
    "multi_shot_prompt = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. A patient such as: ```{allergy_patients.iloc[0]}``` and a patient such as: ```{allergy_patients.iloc[1]}``` are correctly diagnosed with an allergy. \\nIn a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy?\"\n",
    "\n",
    "chain_prompt_1 = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. A patient such as: ```{allergy_patients.iloc[0]}``` and a patient such as: ```{allergy_patients.iloc[1]}``` are correctly diagnosed with an allergy. You will be provided with information about a patient with the end goal of determining if they have an allergy. You will look at the data and then respond with your first thought about what the data is saying. You are not making the final decision. You will give your initial thoughts that will be given to someone else to analyze the data alongside your thoughts.\"\n",
    "chain_prompt_2 = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. A patient such as: ```{allergy_patients.iloc[0]}``` and a patient such as: ```{allergy_patients.iloc[1]}``` are correctly diagnosed with an allergy. You will be provided with information about a patient with the end goal of determining if they have an allergy. You are given the patient data and you are also given a first thought from another source of what they believe the data is saying. You will look at the data and their thought and then respond with your first thought about what the data and source are claiming to generate your own idea. You are not making the final decision. You will give your initial thoughts that will be given to someone else to analyze the data alongside your thoughts.\"\n",
    "chain_prompt_3 = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. A patient such as: ```{allergy_patients.iloc[0]}``` and a patient such as: ```{allergy_patients.iloc[1]}``` are correctly diagnosed with an allergy. In a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy? You will be provided with information about a patient with the end goal of determining if they have an allergy. You are given the patient data and you are also given 2 thoughts from other sources of what they believe the data is saying. You will look at the data and their thoughts and then respond with your thoughts about what the data and source are claiming to generate your own idea. You are making the final decision.\"\n",
    "chain_prompts = [chain_prompt_1, chain_prompt_2, chain_prompt_3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def patient_entry_to_message(entry):\n",
    "    current_year = datetime.datetime.now().year\n",
    "    gender_i = \"He\" if entry[\"gender\"] == \"M\" else \"She\"\n",
    "    gender_p = \"His\" if entry[\"gender\"] == \"M\" else \"Her\"\n",
    "\n",
    "    personal = f\"The patient married status is : {entry['marital']}. \\n{gender_i} is {current_year - entry['birthyear']} years old, is {entry['race']} and {entry['ethnicity']}. \\n{gender_p} income is ${entry['income']:,}.\"\n",
    "    immunization = f\"{gender_i} had {gender_p} {entry['immunization_description']} ({entry['immunization_code']}) immunization on {entry['immunization_date']}\"\n",
    "    observation = f\"{gender_i} has {entry['observation_description']} ({entry['observation_code']}) on {entry['observation_date']} with a value of {entry['observation_value']} {entry['observation_units']}\"\n",
    "    allergies = \"\"#f\"{gender_i} has {entry['allergiy']}\"\n",
    "\n",
    "    return f\"{personal} {immunization} {observation} {allergies}\"\n",
    "\n",
    "def call_llm(prompt, model):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # Set to True if you want to handle streamed response\n",
    "    }\n",
    "    single_response = requests.post(_url, headers=_headers, data=json.dumps(data))\n",
    "    response_json = single_response.json()\n",
    "    return response_json\n",
    "\n",
    "def clean_prediction(response):\n",
    "    # Remove any punctuation\n",
    "    prediction = response.replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").replace(\":\", \"\")\n",
    "\n",
    "    # Guarantee a one word response\n",
    "    if \" \" in prediction:\n",
    "        prediction = prediction.split(\" \")[0]\n",
    "    else:\n",
    "        prediction = prediction\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def save_to_json(results, path, start, end):\n",
    "    # Save a json file with 3 items: The response, the label, and a true or false if the response contains the word \"true\"\n",
    "    json_data = []\n",
    "\n",
    "    for prediction, label in results:\n",
    "        json_data.append({\n",
    "            \"response\": prediction,\n",
    "            \"prediction\": \"true\" in prediction.lower(),\n",
    "            \"label\": label,\n",
    "        })\n",
    "\n",
    "    with open(f\"{path}/{start}-{end}.json\", \"w\") as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "\n",
    "def run_llm_predictions(groups, runs, data, prompts, path, model, start=-1, end=0):\n",
    "\n",
    "    if start > -1 and end > 0:\n",
    "        count = end - start\n",
    "        runs = count // groups\n",
    "\n",
    "    for i in range(runs):\n",
    "        s = time.time()\n",
    "        ss = i * groups + start\n",
    "        ee = ss + groups - 1\n",
    "\n",
    "        private_run_llm_prediction(data, ss, ee, prompts, path, model)\n",
    "\n",
    "        # Clear GPU cache\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        elapse = time.time() - s\n",
    "        print(f\"Current Run: {i+ 1}/{runs} | Elapsed Time: {elapse:.2f} seconds\")\n",
    "\n",
    "def private_run_llm_prediction(data, start, end, prompts, path, model):\n",
    "    results = []\n",
    "    # Iterate patient entries\n",
    "    for index, entry in data.iterrows():\n",
    "        if index < start:\n",
    "            # Skip entry if prior to start\n",
    "            continue\n",
    "        elif index > end:\n",
    "            # Skip prediction if reached 'end'\n",
    "            break\n",
    "        else:\n",
    "            # Run the prediction\n",
    "            message = patient_entry_to_message(entry)\n",
    "            response = []\n",
    "            thought = \"\"\n",
    "\n",
    "            for prompt in prompts:\n",
    "                custom_prompt = f\"{prompt}  \\n```{message}```\"\n",
    "                if len(prompts) > 1:\n",
    "                    custom_prompt += f\" ```{thought}```\"\n",
    "\n",
    "                response = call_llm(custom_prompt, model)\n",
    "                thought = response[\"response\"].strip() + \"\\n\"\n",
    "\n",
    "            # remove any punctuation\n",
    "            prediction = clean_prediction(response[\"response\"].strip())\n",
    "            result = (prediction, bool(entry[\"is_allergy\"]))\n",
    "        results.append(result)\n",
    "\n",
    "    # Save results to a file\n",
    "    save_to_json(results, path, start, end)\n",
    "\n",
    "def calculate_result_stats(path, show_bonus=False):\n",
    "    # Delete Results.json\n",
    "    if os.path.exists(os.path.join(path, 'Results.json')):\n",
    "        os.remove(os.path.join(path, 'Results.json'))\n",
    "\n",
    "    # Get all the files in the directory\n",
    "    files = [f for f in os.listdir(path) if f.endswith('.json')]\n",
    "    # Combine the contents of the files\n",
    "    combined_results = []\n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file), 'r') as f:\n",
    "            lines = json.load(f)\n",
    "            combined_results.extend(lines)\n",
    "\n",
    "    # Write the combined results to a new file\n",
    "    with open(os.path.join(path, 'Results.json'), 'w') as f:\n",
    "        json.dump(combined_results, f, indent=2)\n",
    "\n",
    "\n",
    "    entries = 0\n",
    "    TP, TN, FN, FP, CC, UN = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "    # Read from json file\n",
    "    with open(f\"{path}/Results.json\", \"r\" ) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for entry in data:\n",
    "        response = entry[\"response\"]\n",
    "        prediction = entry[\"prediction\"]\n",
    "        label = entry[\"label\"]\n",
    "        entries += 1\n",
    "\n",
    "        if label == True and prediction == True:\n",
    "            TP += 1\n",
    "        elif label == True and prediction == False:\n",
    "            FN += 1\n",
    "        elif label == False and prediction == True:\n",
    "            FP += 1\n",
    "        elif label == False and prediction == False:\n",
    "            TN += 1\n",
    "        else:\n",
    "            UN += 1\n",
    "        if label == prediction:\n",
    "            CC += 1\n",
    "\n",
    "    # Print out stats\n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    try:\n",
    "        total = TP + TN + FP + FN\n",
    "        accuracy = (TP + TN) / total if total != 0 else 0\n",
    "        precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivisionError: Division by zero occurred in accuracy, precision, or recall calculation.\")\n",
    "\n",
    "    print(f\"Amount of entries: {entries}\")\n",
    "    print(f\"Amount Correct: {CC}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Unknown: {UN}\")\n",
    "    if show_bonus:\n",
    "        print(f\"True Positives: {TP}\")\n",
    "        print(f\"True Negatives: {TN}\")\n",
    "        print(f\"False Positives: {FP}\")\n",
    "        print(f\"False Negatives: {FN}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "def print_model_results(c_model):\n",
    "    print(f\"Model: {c_model} Results\")\n",
    "    path = f\"results/{c_model}\"\n",
    "    print(\"\\nZero Shot\")\n",
    "    calculate_result_stats(f\"{path}/Zero Shot\")\n",
    "\n",
    "    print(\"\\n\\nOne Shot\")\n",
    "    calculate_result_stats(f\"{path}/One Shot\")\n",
    "\n",
    "    print(\"\\n\\nMulti Shot\")\n",
    "    calculate_result_stats(f\"{path}/Multi Shot\")\n",
    "\n",
    "    print(\"\\n\\nChain Shot\")\n",
    "    calculate_result_stats(f\"{path}/Chain\")"
   ],
   "id": "e915addda22b49bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run LLM predictions (Zero, One, Multi Shot, Chain Prompt)",
   "id": "c0858e703cf8a452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_all_prediction_types(group_count, run_count, group_count_2, run_count_2, result_path, model):\n",
    "    # Zero shot\n",
    "    run_llm_predictions(group_count, run_count, patients_shuffle, [zero_shot_prompt], f\"{result_path}/Zero Shot\", model)\n",
    "    #\n",
    "    # One Shot\n",
    "    run_llm_predictions(group_count, run_count, patients_shuffle, [one_shot_prompt], f\"{result_path}/One Shot\", model)\n",
    "\n",
    "    # Multi Shot\n",
    "    run_llm_predictions(group_count, run_count, patients_shuffle, [multi_shot_prompt], f\"{result_path}/Multi Shot\", model)\n",
    "\n",
    "    # Change to only run on 3,000 entries (25,000 takes too long) for Chain Prompts\n",
    "    chain_path = f\"{result_path}/Chain\"\n",
    "    run_llm_predictions(group_count_2, run_count_2, patients_shuffle, [chain_prompts], chain_path, model)\n",
    "\n",
    "shot_groups = 1000\n",
    "shot_runs = 25\n",
    "chain_groups = 1000\n",
    "chain_runs = 3\n",
    "\n",
    "run_all_prediction_types(shot_groups, shot_runs, chain_groups, chain_runs, \"results/gemma3\", \"gemma3:12b\")\n",
    "run_all_prediction_types(shot_groups, shot_runs, chain_groups, chain_runs, \"results/llama3.2\", \"llama3.2:latest\")"
   ],
   "id": "d37b4eeb76ca878",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Stats of the results",
   "id": "22a2f1fb80820a68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print_model_results(\"gemma3\")\n",
    "print_model_results(\"llama3.2\")"
   ],
   "id": "a0988961976fdc51",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
