{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load patient data and imports",
   "id": "dad2ed8b25de6f84"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T19:04:58.695615Z",
     "start_time": "2025-04-08T19:04:52.930687Z"
    }
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_url = \"http://localhost:11434/api/generate\"\n",
    "_headers = {\"Content-Type\": \"application/json\"}\n",
    "_model = \"gemma3:12b\"\n",
    "patients_original = pandas.read_csv(\"data/allergy_patients.csv\", low_memory=False)\n",
    "print(f\"Patients: {len(patients_original):,}\")\n",
    "\n",
    "# Shuffle data\n",
    "patients_shuffle = patients_original.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "group_count = 1000\n",
    "run_count = 3\n",
    "\n",
    "allergy_patients = patients_shuffle[patients_shuffle[\"is_allergy\"] == 1].sample(n=2, random_state=1)\n",
    "chain_prompt_1 = f\"You will be provided with information about a patient with the end goal of determining if they have an allergy. You will look at the data and then respond with your first thought about what the data is saying. You are not making the final decision. You will give your initial thoughts that will be given to someone else to analyze the data alongside your thoughts.\"\n",
    "chain_prompt_2 = f\"You will be provided with information about a patient with the end goal of determining if they have an allergy. You are given the patient data and you are also given a first thought from another source of what they believe the data is saying. You will look at the data and their thought and then respond with your first thought about what the data and source are claiming to generate your own idea. You are not making the final decision. You will give your initial thoughts that will be given to someone else to analyze the data alongside your thoughts.\"\n",
    "chain_prompt_3 = f\"In a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy? You will be provided with information about a patient with the end goal of determining if they have an allergy. You are given the patient data and you are also given 2 thoughts from other sources of what they believe the data is saying. You will look at the data and their thoughts and then respond with your first thought about what the data and source are claiming to generate your own idea. You are making the final decision.\"\n",
    "chain_prompts = [chain_prompt_1, chain_prompt_2, chain_prompt_3]\n",
    "zero_shot_prompt = f\"In a one word answer either 'True' or 'False' (no punctuation) and based on the following information, does the patient have an allergy?\"\n",
    "one_shot_prompt = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. In a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy?\"\n",
    "multi_shot_prompt = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. A patient such as: ```{allergy_patients.iloc[0]}``` and a patient such as: ```{allergy_patients.iloc[1]}``` are correctly diagnosed with an allergy. \\nIn a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy?\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients: 2,007,217\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T19:05:02.566799Z",
     "start_time": "2025-04-08T19:05:02.559104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def patient_entry_to_message(entry):\n",
    "    current_year = datetime.datetime.now().year\n",
    "    gender_i = \"He\" if entry[\"gender\"] == \"M\" else \"She\"\n",
    "    gender_p = \"His\" if entry[\"gender\"] == \"M\" else \"Her\"\n",
    "\n",
    "    personal = f\"The patient married status is : {entry['marital']}. {gender_i} is {current_year - entry['birthyear']} years old, is {entry['race']} and {entry['ethnicity']}. {gender_p} income is {entry['income']}.\"\n",
    "    immunization = f\"{gender_i} has {gender_p} {entry['immunization_description']} ({entry['immunization_code']}) immunization on {entry['immunization_date']}\"\n",
    "    observation = f\"{gender_i} has {entry['observation_description']} ({entry['observation_code']}) on {entry['observation_date']} with a value of {entry['observation_value']} {entry['observation_units']}\"\n",
    "    allergies = \"\"#f\"{gender_i} has {entry['allergiy']}\"\n",
    "\n",
    "    return f\"{personal} {immunization} {observation} {allergies}\"\n",
    "\n",
    "def call_llm(prompt, model):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # Set to True if you want to handle streamed response\n",
    "    }\n",
    "    single_response = requests.post(_url, headers=_headers, data=json.dumps(data))\n",
    "    response_json = single_response.json()\n",
    "    return response_json\n",
    "\n",
    "def llm_multimessage(prompt):\n",
    "    prompt = f\"In a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy? {prompt}\"\n",
    "    data = {\n",
    "        \"model\": _model,\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who explains things clearly and concisely.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ], \"stream\": False}\n",
    "    multi_response = requests.post(_url, headers=_headers, data=json.dumps(data), stream=True)\n",
    "    print(multi_response.json()[\"message\"][\"content\"])\n",
    "\n",
    "def run_llm_predictions2(group, data, path, prompt, model=_model, start=0, end=0, runs=0):\n",
    "    results = []\n",
    "\n",
    "    # If runs is zero start & end are expected to be set to valid numbers\n",
    "    if runs == 0:\n",
    "        count = end -start\n",
    "        runs = count // group\n",
    "\n",
    "    for i in range(runs):\n",
    "        s = time.time()\n",
    "        ss = i * group\n",
    "        ee = ss + group - 1\n",
    "\n",
    "        # Iterate patient entries\n",
    "        for index, entry in data.iterrows():\n",
    "            if index < ss:\n",
    "                # Skip entry if prior to start\n",
    "                continue\n",
    "            elif index > ee:\n",
    "                # Skip prediction if reached 'end'\n",
    "                break\n",
    "            else:\n",
    "                # Run the prediction\n",
    "                message = patient_entry_to_message(entry)\n",
    "                response = call_llm(prompt + message, model)\n",
    "                result = (response[\"response\"].strip(), bool(entry[\"is_allergy\"]))\n",
    "                results.append(result)\n",
    "                print(f\"Completed entry {index}/{count}\", flush=True)\n",
    "\n",
    "        model_str = model.split(\":\")[0]\n",
    "        # Save results to a file\n",
    "        with open(f\"{path}/{model_str}/{start}-{end}.txt\", \"w\") as file:\n",
    "            for prediction, label in results:\n",
    "                file.write(f\"Prediction: {prediction}, Label: {label}\\n\")\n",
    "\n",
    "        elapse = time.time() - s\n",
    "        print(f\"Current Run: {i+ 1}/{runs} | Elapsed Time: {elapse:.2f} seconds\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def run_llm_predictions(groups, runs, data, path, prompts, model=_model):\n",
    "    results = []\n",
    "    for i in range(runs):\n",
    "        s = time.time()\n",
    "\n",
    "        start = i * groups\n",
    "        end = start + groups - 1\n",
    "\n",
    "        # Iterate patient entries\n",
    "        for index, entry in data.iterrows():\n",
    "            if index < start:\n",
    "                # Skip entry if prior to start\n",
    "                continue\n",
    "            elif index > end:\n",
    "                # Skip prediction if reached 'end'\n",
    "                break\n",
    "            else:\n",
    "                # Run the prediction\n",
    "                message = patient_entry_to_message(entry)\n",
    "                response = []\n",
    "                thought = \"\"\n",
    "\n",
    "                for prompt in prompts:\n",
    "                    custom_prompt = f\"{prompt}  \\n```{message}```\"\n",
    "                    if len(prompts) > 1:\n",
    "                        custom_prompt += f\" ```{thought}```\"\n",
    "\n",
    "                    response = call_llm(custom_prompt, model)\n",
    "                    thought = response[\"response\"].strip() + \"\\n\"\n",
    "\n",
    "                # remove any punctuation\n",
    "                prediction = response[\"response\"].strip()\n",
    "                prediction = prediction.replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").replace(\":\", \"\")\n",
    "                result = (prediction, bool(entry[\"is_allergy\"]))\n",
    "                results.append(result)\n",
    "\n",
    "\n",
    "        model_str = model.split(\":\")[0]\n",
    "        # Save results to a file\n",
    "        with open(f\"{path}/{model_str}/{start}-{end}.txt\", \"w\") as file:\n",
    "            for prediction, label in results:\n",
    "                file.write(f\"Prediction: {prediction}, Label: {label}\\n\")\n",
    "\n",
    "        elapse = time.time() - s\n",
    "        print(f\"Current Run: {i+ 1}/{runs} | Elapsed Time: {elapse:.2f} seconds\")\n",
    "\n",
    "def calculate_result_stats(groups, runs, path, model=_model, show_bonus=False):\n",
    "    results = []\n",
    "    for i in range(runs):\n",
    "        start = i * groups\n",
    "        end = start + groups - 1\n",
    "\n",
    "        model_str = model.split(\":\")[0]\n",
    "        # Read results from file\n",
    "        with open(f\"{path}/{model_str}/{start}-{end}.txt\", \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                line_split = line.strip().split(\",\")\n",
    "\n",
    "                y_pred = line_split[0].split(\":\")[1].strip()\n",
    "                y_label = line_split[1].split(\":\")[1].strip()\n",
    "\n",
    "                result = (y_pred, y_label)\n",
    "                results.append(result)\n",
    "\n",
    "    # Calculate & print stats\n",
    "    TP, TN, FN, FP, CC = 0, 0, 0, 0, 0\n",
    "    for prediction, label in results:\n",
    "\n",
    "        if label == \"True\" and prediction == \"True\":\n",
    "            TP += 1\n",
    "        elif label == \"True\" and prediction == \"False\":\n",
    "            FN += 1\n",
    "        elif label == \"False\" and prediction == \"True\":\n",
    "            FP += 1\n",
    "        elif label == \"False\" and prediction == \"False\":\n",
    "            TN += 1\n",
    "\n",
    "        if label == prediction:\n",
    "            CC += 1\n",
    "\n",
    "    # Print out stats\n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    try:\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivisionError: Division by zero occurred in accuracy, precision, or recall calculation.\")\n",
    "\n",
    "    print(f\"Amount of entries: {len(results)}\")\n",
    "    print(f\"Amount Correct: {CC}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    if show_bonus:\n",
    "        print(f\"True Positives: {TP}\")\n",
    "        print(f\"True Negatives: {TN}\")\n",
    "        print(f\"False Positives: {FP}\")\n",
    "        print(f\"False Negatives: {FN}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")"
   ],
   "id": "bdc70f4657afc0c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run LLM predictions using gemma (Zero, One, Multi Shot)",
   "id": "c0858e703cf8a452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Zero shot\n",
    "run_llm_predictions(group_count, run_count, patients_shuffle, \"results/Zero Shot\", [zero_shot_prompt])\n",
    "\n",
    "# One Shot\n",
    "run_llm_predictions(group_count, run_count, patients_shuffle, \"results/One Shot\", [one_shot_prompt])\n",
    "\n",
    "# Multi Shot\n",
    "run_llm_predictions(group_count, run_count, patients_shuffle, \"results/Multi Shot\", [multi_shot_prompt])\n"
   ],
   "id": "d37b4eeb76ca878",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Stats of the results",
   "id": "22a2f1fb80820a68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Zero Shot\")\n",
    "calculate_result_stats(group_count, run_count, \"results/Zero Shot\")\n",
    "\n",
    "print(\"\\n\\nOne Shot\")\n",
    "calculate_result_stats(group_count, run_count, \"results/One Shot\")\n",
    "\n",
    "print(\"\\n\\nMulti Shot\")\n",
    "calculate_result_stats(group_count, run_count, \"results/Multi Shot\")"
   ],
   "id": "a0988961976fdc51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chain of thought",
   "id": "4b0829ba3de7dd73"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-08T19:05:11.971050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "group_count = 1000\n",
    "run_count = 3\n",
    "\n",
    "run_llm_predictions(group_count, run_count, patients_shuffle, \"results/Chain\", chain_prompts, \"llama3.2:latest\")\n",
    "\n",
    "# run_llm_predictions(group_count, run_count, patients_shuffle, \"results/Zero Shot\", zero_shot_prompt, \"gemma3:12b\")\n",
    "\n",
    "# run_llm_predictions(group_count, run_count, patients_shuffle, \"results/Zero Shot\", zero_shot_prompt, \"deepseek-r1:1.5b\")\n",
    "\n",
    "\n",
    "# Shows stats for each model\n",
    "# calculate_result_stats(group_count, run_count, \"results/Zero Shot\", \"gemma3:12b\")\n",
    "# calculate_result_stats(group_count, run_count, \"results/Zero Shot\", \"deepseek-r1:1.5b\")\n",
    "calculate_result_stats(group_count, run_count, \"results/Chain\", \"llama3.2:latest\")"
   ],
   "id": "e6f3fbb5d56ee682",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
