{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load patient data and imports",
   "id": "dad2ed8b25de6f84"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T20:35:27.846295Z",
     "start_time": "2025-04-09T20:35:11.668824Z"
    }
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_url = \"http://localhost:11434/api/generate\"\n",
    "_headers = {\"Content-Type\": \"application/json\"}\n",
    "patients_original = pandas.read_csv(\"data/allergy_patients.csv\", low_memory=False)\n",
    "\n",
    "print(f\"Patients: {len(patients_original):,}\")\n",
    "\n",
    "new_dataset = False\n",
    "if new_dataset:\n",
    "    # Shuffle data\n",
    "    patients_shuffle = patients_original.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Save dataset to csv\n",
    "    patients_shuffle.to_csv('data/shuffled_data.csv', index=False, header=True)\n",
    "else:\n",
    "    # Used to load existing shuffle dataset. This is for testing on same set with different models.\n",
    "    patients_shuffle = pandas.read_csv(\"data/shuffled_data.csv\", low_memory=False)\n",
    "\n",
    "\n",
    "# Chain Prompts\n",
    "allergy_patients = patients_shuffle[patients_shuffle[\"is_allergy\"] == 1].sample(n=2, random_state=1)\n",
    "chain_prompt_1 = f\"You will be provided with information about a patient with the end goal of determining if they have an allergy. You will look at the data and then respond with your first thought about what the data is saying. You are not making the final decision. You will give your initial thoughts that will be given to someone else to analyze the data alongside your thoughts.\"\n",
    "chain_prompt_2 = f\"You will be provided with information about a patient with the end goal of determining if they have an allergy. You are given the patient data and you are also given a first thought from another source of what they believe the data is saying. You will look at the data and their thought and then respond with your first thought about what the data and source are claiming to generate your own idea. You are not making the final decision. You will give your initial thoughts that will be given to someone else to analyze the data alongside your thoughts.\"\n",
    "chain_prompt_3 = f\"In a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy? You will be provided with information about a patient with the end goal of determining if they have an allergy. You are given the patient data and you are also given 2 thoughts from other sources of what they believe the data is saying. You will look at the data and their thoughts and then respond with your thoughts about what the data and source are claiming to generate your own idea. You are making the final decision.\"\n",
    "chain_prompts = [chain_prompt_1, chain_prompt_2, chain_prompt_3]\n",
    "\n",
    "# Shot prompts\n",
    "zero_shot_prompt = f\"In a one word answer either 'True' or 'False' (no punctuation) and based on the following information, does the patient have an allergy?\"\n",
    "one_shot_prompt = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. In a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy?\"\n",
    "multi_shot_prompt = f\"You are a medical professional who specializes in diagnosing patients who have allergies based on a small description of their medical records\\n. A patient such as: ```{allergy_patients.iloc[0]}``` and a patient such as: ```{allergy_patients.iloc[1]}``` are correctly diagnosed with an allergy. \\nIn a one word answer either 'True' or 'False' and based on the following information, does the patient have an allergy?\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients: 2,007,217\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def patient_entry_to_message(entry):\n",
    "    current_year = datetime.datetime.now().year\n",
    "    gender_i = \"He\" if entry[\"gender\"] == \"M\" else \"She\"\n",
    "    gender_p = \"His\" if entry[\"gender\"] == \"M\" else \"Her\"\n",
    "\n",
    "    personal = f\"The patient married status is : {entry['marital']}. \\n{gender_i} is {current_year - entry['birthyear']} years old, is {entry['race']} and {entry['ethnicity']}. \\n{gender_p} income is ${entry['income']:,}.\"\n",
    "    immunization = f\"{gender_i} had {gender_p} {entry['immunization_description']} ({entry['immunization_code']}) immunization on {entry['immunization_date']}\"\n",
    "    observation = f\"{gender_i} has {entry['observation_description']} ({entry['observation_code']}) on {entry['observation_date']} with a value of {entry['observation_value']} {entry['observation_units']}\"\n",
    "    allergies = \"\"#f\"{gender_i} has {entry['allergiy']}\"\n",
    "\n",
    "    return f\"{personal} {immunization} {observation} {allergies}\"\n",
    "\n",
    "def call_llm(prompt, model):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # Set to True if you want to handle streamed response\n",
    "    }\n",
    "    single_response = requests.post(_url, headers=_headers, data=json.dumps(data))\n",
    "    response_json = single_response.json()\n",
    "    return response_json\n",
    "\n",
    "def clean_prediction(response):\n",
    "    # Remove any punctuation\n",
    "    prediction = response.replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").replace(\":\", \"\")\n",
    "\n",
    "    # Guarantee a one word response\n",
    "    if \" \" in prediction:\n",
    "        prediction = prediction.split(\" \")[0]\n",
    "    else:\n",
    "        prediction = prediction\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def run_llm_predictions(groups, runs, data, path, prompts, model):\n",
    "    for i in range(runs):\n",
    "        results = []\n",
    "        s = time.time()\n",
    "\n",
    "        start = i * groups\n",
    "        end = start + groups - 1\n",
    "\n",
    "        # Iterate patient entries\n",
    "        for index, entry in data.iterrows():\n",
    "            if index < start:\n",
    "                # Skip entry if prior to start\n",
    "                continue\n",
    "            elif index > end:\n",
    "                # Skip prediction if reached 'end'\n",
    "                break\n",
    "            else:\n",
    "                # Run the prediction\n",
    "                message = patient_entry_to_message(entry)\n",
    "                response = []\n",
    "                thought = \"\"\n",
    "\n",
    "                for prompt in prompts:\n",
    "                    custom_prompt = f\"{prompt}  \\n```{message}```\"\n",
    "                    if len(prompts) > 1:\n",
    "                        custom_prompt += f\" ```{thought}```\"\n",
    "\n",
    "                    response = call_llm(custom_prompt, model)\n",
    "                    thought = response[\"response\"].strip() + \"\\n\"\n",
    "\n",
    "                # remove any punctuation\n",
    "                prediction = clean_prediction(response[\"response\"].strip())\n",
    "                result = (prediction, bool(entry[\"is_allergy\"]))\n",
    "                results.append(result)\n",
    "\n",
    "\n",
    "        # Save results to a file\n",
    "        # model_str = model.split(\":\")[0]\n",
    "        #with open(f\"{path}/{model_str}/{start}-{end}.txt\", \"w\") as file:\n",
    "        with open(f\"{path}/{start}-{end}.txt\", \"w\") as file:\n",
    "            for prediction, label in results:\n",
    "                file.write(f\"Prediction: {prediction} | Label: {label}\\n\")\n",
    "\n",
    "        elapse = time.time() - s\n",
    "        print(f\"Current Run: {i+ 1}/{runs} | Elapsed Time: {elapse:.2f} seconds\")\n",
    "\n",
    "def run_llm_predictions_on_set(start, end, groups, data, path, prompts, model):\n",
    "\n",
    "    count = end - start\n",
    "    runs = count // groups\n",
    "\n",
    "    for i in range(runs):\n",
    "        ss = i * groups + start\n",
    "        ee = ss + groups - 1\n",
    "\n",
    "        s = time.time()\n",
    "        results = []\n",
    "        # Done in a single run\n",
    "        for index, entry in data.iterrows():\n",
    "            if index < ss:\n",
    "                continue\n",
    "            elif index > ee:\n",
    "                break\n",
    "            else:\n",
    "                # Run the prediction\n",
    "                message = patient_entry_to_message(entry)\n",
    "                response = []\n",
    "                thought = \"\"\n",
    "\n",
    "                for prompt in prompts:\n",
    "                    custom_prompt = f\"{prompt}  \\n```{message}```\"\n",
    "                    if len(prompts) > 1:\n",
    "                        custom_prompt += f\" ```{thought}```\"\n",
    "\n",
    "                    response = call_llm(custom_prompt, model)\n",
    "                    thought = response[\"response\"].strip() + \"\\n\"\n",
    "\n",
    "                # remove any punctuation\n",
    "                prediction = clean_prediction(response[\"response\"].strip())\n",
    "                result = (prediction, bool(entry[\"is_allergy\"]))\n",
    "                results.append(result)\n",
    "\n",
    "        # Save results to a file\n",
    "        with open(f\"{path}/{ss}-{ee}.txt\", \"w\") as file:\n",
    "            for prediction, label in results:\n",
    "                file.write(f\"Prediction: {prediction} | Label: {label}\\n\")\n",
    "\n",
    "        elapse = time.time() - s\n",
    "        print(f\"Current Run: {i+1}/{runs} Elapsed Time: {elapse:.2f} seconds\")\n",
    "\n",
    "def calculate_result_stats(path, show_bonus=False):\n",
    "    results = []\n",
    "    # Read results from file\n",
    "    with open(f\"{path}/Results.txt\", \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            line_split = line.strip().split(\"|\")\n",
    "\n",
    "            y_pred = line_split[0].split(\":\")[1].strip()\n",
    "            y_label = line_split[1].split(\":\")[1].strip()\n",
    "\n",
    "            result = (y_pred, y_label)\n",
    "            results.append(result)\n",
    "\n",
    "    # Calculate & print stats\n",
    "    TP, TN, FN, FP, CC, UN = 0, 0, 0, 0, 0, 0\n",
    "    for prediction, label in results:\n",
    "\n",
    "        if label == \"True\" and prediction == \"True\":\n",
    "            TP += 1\n",
    "        elif label == \"True\" and prediction == \"False\":\n",
    "            FN += 1\n",
    "        elif label == \"False\" and prediction == \"True\":\n",
    "            FP += 1\n",
    "        elif label == \"False\" and prediction == \"False\":\n",
    "            TN += 1\n",
    "        else:\n",
    "            UN += 1\n",
    "        if label == prediction:\n",
    "            CC += 1\n",
    "\n",
    "    # Print out stats\n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    try:\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivisionError: Division by zero occurred in accuracy, precision, or recall calculation.\")\n",
    "\n",
    "    print(f\"Amount of entries: {len(results)}\")\n",
    "    print(f\"Amount Correct: {CC}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Unknown: {UN}\")\n",
    "    if show_bonus:\n",
    "        print(f\"True Positives: {TP}\")\n",
    "        print(f\"True Negatives: {TN}\")\n",
    "        print(f\"False Positives: {FP}\")\n",
    "        print(f\"False Negatives: {FN}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "def calculate_result_stats_on_set(path, start, end, show_bonus=False):\n",
    "    results = []\n",
    "    # Read results from file\n",
    "    with open(f\"{path}/Results.txt\", \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        for index, line in enumerate(lines):\n",
    "            if index < start:\n",
    "                continue\n",
    "            elif index > end:\n",
    "                break\n",
    "            else:\n",
    "                # Run the prediction\n",
    "                line_split = line.strip().split(\"|\")\n",
    "\n",
    "                y_pred = line_split[0].split(\":\")[1].strip()\n",
    "                y_label = line_split[1].split(\":\")[1].strip()\n",
    "\n",
    "                result = (y_pred, y_label)\n",
    "                results.append(result)\n",
    "\n",
    "    # Calculate & print stats\n",
    "    TP, TN, FN, FP, CC, UN = 0, 0, 0, 0, 0, 0\n",
    "    for prediction, label in results:\n",
    "\n",
    "        if label == \"True\" and prediction == \"True\":\n",
    "            TP += 1\n",
    "        elif label == \"True\" and prediction == \"False\":\n",
    "            FN += 1\n",
    "        elif label == \"False\" and prediction == \"True\":\n",
    "            FP += 1\n",
    "        elif label == \"False\" and prediction == \"False\":\n",
    "            TN += 1\n",
    "        else:\n",
    "            print(f\"Unknown label: {label} | Unknown prediction: {prediction}\")\n",
    "            UN += 1\n",
    "        if label == prediction:\n",
    "            CC += 1\n",
    "\n",
    "    # Print out stats\n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    try:\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivisionError: Division by zero occurred in accuracy, precision, or recall calculation.\")\n",
    "\n",
    "    print(f\"Amount of entries: {len(results)}\")\n",
    "    print(f\"Amount Correct: {CC}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Unknown: {UN}\")\n",
    "    if show_bonus:\n",
    "        print(f\"True Positives: {TP}\")\n",
    "        print(f\"True Negatives: {TN}\")\n",
    "        print(f\"False Positives: {FP}\")\n",
    "        print(f\"False Negatives: {FN}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "def combine_txt_results(path):\n",
    "    # Delete file if it exists\n",
    "    if os.path.exists(os.path.join(path, 'Results.txt')):\n",
    "        os.remove(os.path.join(path, 'Results.txt'))\n",
    "\n",
    "    # Get all the files in the directory\n",
    "    files = [f for f in os.listdir(path) if f.endswith('.txt')]\n",
    "\n",
    "    # Combine the contents of the files\n",
    "    combined_results = []\n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            combined_results.extend(lines)\n",
    "\n",
    "    # Write the combined results to a new file\n",
    "    with open(os.path.join(path, 'Results.txt'), 'w') as f:\n",
    "        f.writelines(combined_results)\n",
    "\n",
    "def print_model_results(c_model):\n",
    "    print(f\"Model: {c_model} Results\")\n",
    "    path = f\"results/{c_model}\"\n",
    "    combine_txt_results(f\"{path}/Zero Shot\")\n",
    "    combine_txt_results(f\"{path}/One Shot\")\n",
    "    combine_txt_results(f\"{path}/Multi Shot\")\n",
    "    combine_txt_results(f\"{path}/Chain\")\n",
    "\n",
    "    print(\"\\nZero Shot\")\n",
    "    calculate_result_stats(f\"{path}/Zero Shot\")\n",
    "\n",
    "    print(\"\\n\\nOne Shot\")\n",
    "    calculate_result_stats(f\"{path}/One Shot\")\n",
    "\n",
    "    print(\"\\n\\nMulti Shot\")\n",
    "    calculate_result_stats(f\"{path}/Multi Shot\")\n",
    "\n",
    "    print(\"\\n\\nChain Shot\")\n",
    "    calculate_result_stats(f\"{path}/Chain\")"
   ],
   "id": "bdc70f4657afc0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run LLM predictions (Zero, One, Multi Shot, Chain Prompt)",
   "id": "c0858e703cf8a452"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:36:52.350907Z",
     "start_time": "2025-04-09T20:36:04.821194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_all_prediction_types(group_count, run_count, group_count_2, run_count_2, result_path, model):\n",
    "    # Zero shot\n",
    "    run_llm_predictions(group_count, run_count, patients_shuffle, f\"{result_path}/Zero Shot\", [zero_shot_prompt], model)\n",
    "    #\n",
    "    # One Shot\n",
    "    run_llm_predictions(group_count, run_count, patients_shuffle, f\"{result_path}/One Shot\", [one_shot_prompt], model)\n",
    "\n",
    "    # Multi Shot\n",
    "    run_llm_predictions(group_count, run_count, patients_shuffle, f\"{result_path}/Multi Shot\", [multi_shot_prompt], model)\n",
    "\n",
    "    # Change to only run on 3,000 entries (25,000 takes too long) for Chain Prompts\n",
    "    chain_path = f\"{result_path}/Chain\"\n",
    "    run_llm_predictions(group_count_2, run_count_2, chain_path, [chain_prompts], model)\n",
    "\n",
    "\n",
    "# Run 25,000 entries as group of 1,000 for 25 runs, then run chain prompts for 3,000 entries as group of 1000 for 3 runs.\n",
    "# run_all_prediction_types(1000, 25, 1000, 1, \"results/gemma3\", \"gemma3:12b\")\n",
    "# run_all_prediction_types(1000, 25, 1000, 1, \"results/llama3.2\", \"llama3.2:latest\")\n",
    "run_all_prediction_types(1, 1, 1, 1, \"results/gemma3\", \"gemma3:12b\")\n",
    "run_all_prediction_types(1, 1, 1, 1, \"results/llama3.2\", \"llama3.2:latest\")"
   ],
   "id": "d37b4eeb76ca878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Run: 1/1 | Elapsed Time: 33.42 seconds\n",
      "Current Run: 1/1 | Elapsed Time: 10.60 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 19\u001B[0m\n\u001B[1;32m     13\u001B[0m     run_llm_predictions(group_count_2, run_count_2, chain_path, [chain_prompts], model)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Run 25,000 entries as group of 1,000 for 25 runs, then run chain prompts for 3,000 entries as group of 1000 for 3 runs.\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# run_all_prediction_types(1000, 25, 1000, 1, \"results/gemma3\", \"gemma3:12b\")\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# run_all_prediction_types(1000, 25, 1000, 1, \"results/llama3.2\", \"llama3.2:latest\")\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m run_all_prediction_types(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults/gemma3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgemma3:12b\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     20\u001B[0m run_all_prediction_types(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults/llama3.2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllama3.2:latest\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[50], line 9\u001B[0m, in \u001B[0;36mrun_all_prediction_types\u001B[0;34m(group_count, run_count, group_count_2, run_count_2, result_path, model)\u001B[0m\n\u001B[1;32m      6\u001B[0m run_llm_predictions(group_count, run_count, patients_shuffle, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/One Shot\u001B[39m\u001B[38;5;124m\"\u001B[39m, [one_shot_prompt], model)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Multi Shot\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m run_llm_predictions(group_count, run_count, patients_shuffle, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/Multi Shot\u001B[39m\u001B[38;5;124m\"\u001B[39m, [multi_shot_prompt], model)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Change to only run on 3,000 entries (25,000 takes too long) for Chain Prompts\u001B[39;00m\n\u001B[1;32m     12\u001B[0m chain_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/Chain\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "Cell \u001B[0;32mIn[47], line 44\u001B[0m, in \u001B[0;36mrun_llm_predictions\u001B[0;34m(groups, runs, data, path, prompts, model)\u001B[0m\n\u001B[1;32m     41\u001B[0m end \u001B[38;5;241m=\u001B[39m start \u001B[38;5;241m+\u001B[39m groups \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# Iterate patient entries\u001B[39;00m\n\u001B[0;32m---> 44\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, entry \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;241m<\u001B[39m start:\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;66;03m# Skip entry if prior to start\u001B[39;00m\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/AIH/lib/python3.11/site-packages/pandas/core/frame.py:1553\u001B[0m, in \u001B[0;36mDataFrame.iterrows\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1551\u001B[0m klass \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor_sliced\n\u001B[1;32m   1552\u001B[0m using_cow \u001B[38;5;241m=\u001B[39m using_copy_on_write()\n\u001B[0;32m-> 1553\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues):\n\u001B[1;32m   1554\u001B[0m     s \u001B[38;5;241m=\u001B[39m klass(v, index\u001B[38;5;241m=\u001B[39mcolumns, name\u001B[38;5;241m=\u001B[39mk)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1555\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m using_cow \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mis_single_block:\n",
      "File \u001B[0;32m~/anaconda3/envs/AIH/lib/python3.11/site-packages/pandas/core/frame.py:12664\u001B[0m, in \u001B[0;36mDataFrame.values\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m  12590\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m  12591\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m  12592\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m  12593\u001B[0m \u001B[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001B[39;00m\n\u001B[1;32m  12594\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  12662\u001B[0m \u001B[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001B[39;00m\n\u001B[1;32m  12663\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m> 12664\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mas_array()\n",
      "File \u001B[0;32m~/anaconda3/envs/AIH/lib/python3.11/site-packages/pandas/core/internals/managers.py:1694\u001B[0m, in \u001B[0;36mBlockManager.as_array\u001B[0;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[1;32m   1692\u001B[0m         arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1693\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1694\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interleave(dtype\u001B[38;5;241m=\u001B[39mdtype, na_value\u001B[38;5;241m=\u001B[39mna_value)\n\u001B[1;32m   1695\u001B[0m     \u001B[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001B[39;00m\n\u001B[1;32m   1696\u001B[0m     \u001B[38;5;66;03m# to further copy if copy=True or setting na_value\u001B[39;00m\n\u001B[1;32m   1698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_value \u001B[38;5;129;01mis\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n",
      "File \u001B[0;32m~/anaconda3/envs/AIH/lib/python3.11/site-packages/pandas/core/internals/managers.py:1735\u001B[0m, in \u001B[0;36mBlockManager._interleave\u001B[0;34m(self, dtype, na_value)\u001B[0m\n\u001B[1;32m   1733\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[1;32m   1734\u001B[0m     rl \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mmgr_locs\n\u001B[0;32m-> 1735\u001B[0m     arr \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mget_values(dtype)\n\u001B[1;32m   1736\u001B[0m     result[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m arr\n\u001B[1;32m   1737\u001B[0m     itemmask[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/AIH/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2588\u001B[0m, in \u001B[0;36mNumpyBlock.get_values\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   2586\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_values\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype: DtypeObj \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m   2587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;241m==\u001B[39m _dtype_obj:\n\u001B[0;32m-> 2588\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(_dtype_obj)\n\u001B[1;32m   2589\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Stats of the results",
   "id": "22a2f1fb80820a68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print_model_results(\"gemma3\")\n",
    "print_model_results(\"llama3.2\")"
   ],
   "id": "a0988961976fdc51",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
